{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc29b79-8fc7-4bcc-88f4-f277a4add0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hemant\\blackrock_assignment_work\\logs\\data_quality_check_using_pandas_or_dask_20240512_1812.log\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import os,sys,glob\n",
    "import dask.dataframe as dd\n",
    "from datetime import datetime\n",
    "import LogConfiguration\n",
    "from configparser import ConfigParser\n",
    "import traceback\n",
    "from Dask_and_core_python import data_quality_check\n",
    "\n",
    "class data_quality_check_with_pandas_dask:\n",
    "    \n",
    "    Filename_Config = r'properties\\Quality_Check_Config.ini'\n",
    "    def __init__(self):\n",
    "        try:\n",
    "            \n",
    "            #configuration to read file\n",
    "            config = ConfigParser()\n",
    "            config.read(self.Filename_Config)     \n",
    "            self.file_log = 'data_quality_check_using_pandas_or_dask'\n",
    "            self.dir_logs = config['path']['dir_logs']\n",
    "            self.dir_input = config['path']['dir_input']\n",
    "            #configuring logs\n",
    "            Log = LogConfiguration.LogConfiguration(os.path.join(self.dir_logs, self.file_log) + '_' + datetime.now().strftime('%Y%m%d_%H%M') + '.log' , self.file_log) \n",
    "            self.logger = Log.getLog()\n",
    "            self.logger.info('log setup completed successfully')\n",
    "        except Exception as e:\n",
    "            self.logger.error('Error while setting up log and path:' + str(e))\n",
    "            trace_info = traceback.format_exc()\n",
    "            self.logger.error(trace_info)\n",
    "            sys.exit(-1)\n",
    "\n",
    "    def extract_data_from_file(self,use_dask=False):\n",
    "        try:\n",
    "            #reading the input file\n",
    "            input_file = glob.glob(os.path.join(self.dir_input, 'stocks_df') + '.csv')\n",
    "            #reading to dataframe\n",
    "            self.use_dask = use_dask\n",
    "            if use_dask:\n",
    "                self.df = dd.read_csv(input_file[0], assume_missing=True)\n",
    "                self.df = self.df.repartition(npartitions=5)\n",
    "            else:\n",
    "                self.df = pd.read_csv(input_file[0], low_memory = False)\n",
    "            \n",
    "            self.logger.info('extract data completed successfully')\n",
    "        except Exception as e:\n",
    "            self.logger.error('Error while extracting data from file:' + str(e))\n",
    "            trace_info = traceback.format_exc()\n",
    "            self.logger.error(trace_info)\n",
    "            sys.exit(-1)\n",
    "\n",
    "    def check_date_format(self, date_str):\n",
    "        try:\n",
    "            date_obj = datetime.strptime(date_str, '%m/%d/%Y')\n",
    "            return date_obj <= datetime.now()\n",
    "        except ValueError:\n",
    "            return False\n",
    "\n",
    "    def date_validity_check(self):\n",
    "        # Convert date column to datetime format and check for valid dates\n",
    "        try:\n",
    "            if self.use_dask == True:\n",
    "                invalid_dates = self.df[~self.df['Date'].apply(self.check_date_format, meta=('Date', 'bool'))]\n",
    "            else:\n",
    "                invalid_dates = self.df[~self.df['Date'].apply(self.check_date_format)]\n",
    "            if len(invalid_dates) > 0:\n",
    "                invalid_dates = invalid_dates.compute() if self.use_dask else invalid_dates\n",
    "                invalid_dates.to_csv('QC_failures/1_qc_failure_dates.csv', index=False)\n",
    "            self.logger.info('date format check completed successfully')\n",
    "        except Exception as e:\n",
    "            trace_info = traceback.format_exc()\n",
    "            print(trace_info)\n",
    "            self.logger.error(trace_info)\n",
    "            self.logger.error(\"Error during date format check:\" + str(e))\n",
    "            \n",
    "    def check_missing_and_negative_values(self):\n",
    "        try:\n",
    "            #check for missing values \n",
    "            missing_values = self.df[['Open', 'High', 'Close', 'Low', 'Volume']].isna()\n",
    "            if len(missing_values) > 0:\n",
    "                \n",
    "                missing_values = self.df[missing_values.any(axis=1)]\n",
    "                missing_values = missing_values.compute() if self.use_dask else missing_values\n",
    "                missing_values.to_csv('QC_failures/2_missing_values.csv', index=False)\n",
    "            \n",
    "            #Check for negative in Open, High, Low, Close, and Volume columns\n",
    "            negative_values = self.df[(self.df[['Open', 'High', 'Low', 'Close', 'Volume']] < 0).any(axis=1)]\n",
    "            if len(negative_values) > 0:\n",
    "                negative_values = negative_values.compute() if self.use_dask else negative_values\n",
    "                negative_values.to_csv('QC_failures/2_negative_values.csv', index=False)\n",
    "            self.logger.info('check missing and negative values completed successfully')\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error in check missing and negative values:\" + str(e))\n",
    "            trace_info = traceback.format_exc()\n",
    "            self.logger.error(trace_info)\n",
    "\n",
    "    def check_change_percent(self):\n",
    "        try:\n",
    "            # Check for change percent values not rounded to two decimal places\n",
    "            incorrect_change_percent = self.df[~(self.df['Change Percent'].round(2) == self.df['Change Percent'])]\n",
    "            if len(incorrect_change_percent) > 0:\n",
    "                incorrect_change_percent = incorrect_change_percent.compute() if self.use_dask else incorrect_change_percent\n",
    "                incorrect_change_percent.to_csv('QC_failures/3_incorrect_decimals_in_change_percent.csv', index=False)\n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error in check_change_percent\", str(e))\n",
    "            \n",
    "    def outcome_value_validity_check(self):\n",
    "        try:\n",
    "            # Filter rows where 'Change Percent' is not null\n",
    "            filtered_df = self.df[self.df['Change Percent'].notnull()]\n",
    "            \n",
    "            # Filter rows where 'Outcome' is not 'PROFIT' or 'LOSS'\n",
    "            invalid_outcome = filtered_df[~filtered_df['Outcome'].isin(['PROFIT', 'LOSS'])]\n",
    "            if len(invalid_outcome) > 0:\n",
    "                invalid_outcome = invalid_outcome.compute() if self.use_dask else invalid_outcome\n",
    "                invalid_outcome.to_csv('QC_failures/4_invalid_outcome_values.csv', index=False)\n",
    "                \n",
    "            self.logger.info('outcome value validity check completed successfully')\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error in outcome_value_validity_check\" + str(e))\n",
    "            trace_info = traceback.format_exc()\n",
    "            self.logger.error(trace_info)\n",
    "\n",
    "    def check_correctness_of_outcome(self):\n",
    "        try:\n",
    "            # Check if Outcome value is correct based on Close and Open prices\n",
    "            incorrect_outcome = self.df[((self.df['Close'] > self.df['Open']) & (self.df['Outcome'] != 'PROFIT')) |\n",
    "                                        ((self.df['Close'] < self.df['Open']) & (self.df['Outcome'] != 'LOSS'))]\n",
    "            if len(incorrect_outcome) > 0:\n",
    "                incorrect_outcome = incorrect_outcome.compute() if self.use_dask else incorrect_outcome\n",
    "                incorrect_outcome.to_csv('QC_failures/5_incorrect_outcome.csv',index=False)\n",
    "            self.logger.info('check correctness of outcome completed sucessfully')\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Error in check_correctness_of_outcome:\" + str(e))\n",
    "            trace_info = traceback.format_exc()\n",
    "            self.logger.error(trace_info)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage:\n",
    "    qc_pandas = data_quality_check_with_pandas_dask()\n",
    "    qc_pandas.extract_data_from_file(use_dask=False) # For Pandas only - Please keep only one enabled\n",
    "    #qc_pandas.extract_data_from_file(use_dask=True)  # For Pandas with Dask - Please keep only one enabled\n",
    "    qc_pandas.date_validity_check()\n",
    "    qc_pandas.check_missing_and_negative_values()\n",
    "    qc_pandas.check_change_percent()\n",
    "    qc_pandas.outcome_value_validity_check()\n",
    "    qc_pandas.check_correctness_of_outcome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe5eb7b-f227-469f-8a1f-2b97a4640cc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f77b96-778b-4b07-a615-23be78271919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
